#!/usr/bin/env python
# coding: utf-8

# # Detailed Course Schedule
# 
# This include all topics covered and all assignments given and when they are due.

# ## Day 1 - 5/18/21 - Introduction and mathematical foundations
# 
# ### Content
# 
#  * Chapter 1: Introduction to data science - [reading](chapter-1-intro-to-data-science) and <a href='../../_slides/chapter-1-slides.html'>slides</a>
#  * Chapter 2: Mathematical foundations - [reading](chapter-2-mathematical-foundations) and <a href='../../_slides/chapter-2-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **DataCamp**
#     * Optional, basic review:
#        * [Introduction to Python](https://www.datacamp.com/courses/intro-to-python-for-data-science)
#        * [Python Data Science Toolbox, Part 1](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)
#     * Required (though it may still be review):
#        * [Intermediate Python](https://www.datacamp.com/courses/intermediate-python-for-data-science), chapters 1-4
#        * [pandas Foundations](https://www.datacamp.com/courses/pandas-foundations), just chapter 1
#        * [Manipulating DataFrames with pandas](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas), just chapter 1
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-2-review-of-cs230) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * Each week, you are expected to read the appropriate chapters from the course notes *before* class.  Since this is the first day for the course, I did not expect you to have read Chapters 1-2 in advance.  But that means that you must now read them together with Chapters 3-4 before next week.
#     * [Chapter 1: Introduction to data science](chapter-1-intro-to-data-science) (adds details to today's class content)
#     * [Chapter 2: Mathematical foundations](chapter-2-mathematical-foundations) (adds details to today's class content)
#     * [Chapter 3: Computational notebooks (Jupyter)](chapter-3-jupyter) (prepares for next week)
#     * [Chapter 4: Python review focusing on pandas and mathematical foundations](chapter-4-review-of-python-and-pandas) (prepares for next week)
#  * **Other**
#     * If you don't already have a Python environment installed on your computer, [see these instructions for installing one](anaconda-installation).  As part of that process, ensure that you can open both Jupyter Lab and VS Code.
#     * Optional: There are many LOYO opportunities from this week's course notes (chapters 1 and 2).  See the syllabus for a definition of LOYO (Learning on Your Own) and consider forming a team and siezing one of the opportunities.

# ---

# ## Day 2 - 5/20/21 - Jupyter and a review of Python and pandas
# 
# ### Content
# 
#  * Chapter 3: Computational notebooks (Jupyter) - [reading](chapter-3-jupyter) and <a href='../../_slides/chapter-3-slides.html'>slides</a>
#  * Chapter 4: Review of Python and pandas - [reading](chapter-4-review-of-python-and-pandas), but no slides
# 
# ### Due before next class
# 
#  * **DataCamp**
#     * [Manipulating DataFrames with pandas](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas), chapters 2-4
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-3) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 5: Before and after, in mathematics and communication](chapter-5-before-and-after)
#     * [Chapter 6: Pandas single-table verbs](chapter-6-single-table-verbs)
# 

# ---

# ## Day 3 - 5/25/21 - Before and after, single-table verbs
# 
# ### Content
# 
#  * Chapter 5: Before and after, in mathematics and communication - [reading](chapter-5-before-and-after) and <a href='../../_slides/chapter-5-slides.html'>slides</a>
#  * Chapter 6: Pandas single-table verbs - [reading](chapter-6-single-table-verbs) and <a href='../../_slides/chapter-6-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Communication exercise**
#     * Create a new Deepnote project and upload into it <a href='../../_static/homework-exercise-on-code-communication.ipynb'>this Jupyter notebook</a> and <a href='../../_static/practice-project-dataset-1.csv'>this CSV file</a>.  (Please be sure to do this in a *new* Deepnote project, rather than just a new folder in an existing project.  Grading becomes error-prone if I have to hunt through your folders for what I'm supposed to grade.)
#     * The first half of the notebook has plenty of comments and explanations, but the second half does not.  Use the principles discussed in class today (and covered in [Chapter 5 of the course notes](chapter-5-before-and-after)) to comment/document/explain the second half of that file.
#     * Follow [Deepnote's instructions](https://docs.deepnote.com/importing-and-exporing/export-to-pdf) for how to export the resulting notebook as a PDF.
#     * Submit that notebook to your instructor through [Blackboard](https://blackboard.bentley.edu).
#  * **DataCamp**
#     * [pandas Foundations](https://www.datacamp.com/courses/pandas-foundations), just chapter 2
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-4-review-of-visualization-in-cs230) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 7: Abstraction in mathematics and computing](chapter-7-abstraction)
#     * [Chapter 8: Version control and GitHub](chapter-8-version-control)
# 

# ---

# ## Day 4 - 5/27/21 - Abstraction and version control
# 
# ### Content
# 
#  * Chapter 7: Abstraction in mathematics and computing - [reading](chapter-7-abstraction) and <a href='../../_slides/chapter-7-slides.html'>slides</a>
#  * Chapter 8: Version control and GitHub - [reading](chapter-8-version-control) and <a href='../../_slides/chapter-8-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Version control exercise**
#     * This assignment is described in the final slide for Chapter 8, linked to above.
#  * **DataCamp**
#     * [Intermediate Python](https://www.datacamp.com/courses/intermediate-python-for-data-science), chapter 5
#     * [Statistical Thinking in Python, Part 1](https://www.datacamp.com/courses/statistical-thinking-in-python-part-1), all chapters
#     * [Introduction to Data Visualization with Python](https://www.datacamp.com/courses/introduction-to-data-visualization-in-python), chapters 1 and 3 only
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-5) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 9: Math and stats in Python](chapter-9-math-and-stats)
#     * [Chapter 10: New visualization tools](chapter-10-visualization)
# 

# ---

# ## Day 5 - 6/1/21 - Math and stats in Python, plus Visualization
# 
# ### Content
# 
#  * Chapter 9: Math and stats in Python - [reading](chapter-9-math-and-stats) and <a href='../../_slides/chapter-9-slides.html'>slides</a>
#  * Chapter 10: New visualization tools - [reading](chapter-10-visualization) and <a href='../../_slides/chapter-10-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Data preparation exercise**
#     * (Some steps of this you have probably already completed.  What's new for everyone is making a project that can easily load the file into Jupyter, so we're ready to experiment with it next week in class.)
#     * Look at the 2016 election data [on this page of NPR's website](https://www.npr.org/2016/11/08/500927768/2016-presidential-election-results-for-each-state).
#     * Extract the table from that page into a CSV file (for example, by copying and pasting into Excel, then touching it up as needed).
#     * Write a Jupyter notebook that imports the CSV file.
#     * Ensure that you remove all rows that are not for entire states (which you can do in Excel or Jupyter, whichever you prefer).
#     * Publish the notebook and the dataset together to a Deepnote or Colab project.
#     * Share the project URL with your instructor by email.
#     * We will use this dataset in class next week.
#  * **DataCamp**
#     * [Merging DataFrames with pandas](https://learn.datacamp.com/courses/merging-dataframes-with-pandas), chapters 1-3
#        * **NOTE:** We will not cover this content in class next week.  We will cover it the subsequent week instead.  But I'm assigning you to do it this week because then you won't have any homework next week, when the project is due, and you'll be able to focus on that instead.
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-6) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 11: Processing the rows of a `DataFrame`](chapter-11-processing-rows)
#  * **Other**
#     * Optional: There are several LOYO opportunities from this week's course notes (chapters 9 and 10).  Consider forming a team and siezing one of the opportunities.

# ---

# ## Day 6 - 6/3/21 - Processing the Rows of a `DataFrame`
# 
# ### Content
# 
#  * Chapter 11: Processing the rows of a `DataFrame` - [reading](chapter-11-processing-rows) and <a href='../../_slides/chapter-11-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **No DataCamp this week, so that you can focus on the project.**
#  * **Reading**
#     * [Chapter 12: Concatenation and Merging](chapter-12-concat-and-merge)
#  * **Other**
#     * Optional: There are a few LOYO opportunities from this week's course notes (chapter 11).  Consider forming a team and siezing one of the opportunities.

# ---

# ## Day 7 - 6/8/21 - Concatenation and Merging
# 
# ### Content
# 
#  * Chapter 12: Concatenation and Merging - [reading](chapter-12-concat-and-merge) and <a href='../../_slides/chapter-12-slides.html'>slides</a>
# 
# ### Due before next class
# 
# It's a light week, because you just did Project 1 and deserve a little time to rest.
# 
#  * **DataCamp**
#     * [Streamlined Data Ingestion with pandas](https://learn.datacamp.com/courses/streamlined-data-ingestion-with-pandas)
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-8) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 13: Miscellaneous Munging Methods (ETL)](chapter-13-etl)
# 

# ---

# ## Day 8 - 6/10/21 - Miscellaneous Munging Methods (ETL)
# 
# ### Content
# 
#  * Chapter 13: Miscellaneous Munging Methods (ETL) - [reading](chapter-13-etl) and <a href='../../_slides/chapter-13-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **DataCamp** (last one for the whole semester!)
#     * [Introduction to SQL for Data Science](https://learn.datacamp.com/courses/introduction-to-sql)
#        * **NOTE:** Bentley's CS350 course goes into this content in far greater detail.  You can see this lesson as a small preview or taste of that course.
#     * [See here for a cheat sheet](big-cheat-sheet.html#before-day-9) of all the content of the above DataCamp lessons.
#  * **Reading**
#     * [Chapter 14: Dashboards](chapter-14-dashboards)
#  * **Other**
#     * Install [Streamlit](https://www.streamlit.io/) (`pip install streamlit`).  Take a screenshot to prove you did so.
#     * [Create a Heroku account](https://signup.heroku.com/).  Then [install the Heroku command-line tools](https://devcenter.heroku.com/articles/getting-started-with-python#set-up).  Ensure that after doing so, you can get to a terminal and run `heroku login` successfully.  Take a screenshot to prove you did so.
#     * Email both screenshots in one email to your instructor.
#  * **Project Planning**
#     * Optional: If you want to get ahead on the final project in a way that's rather easy and fun, start hunting for datasets that cover a topic you're interested in and might want to analyze.  Try to find a dataset that's pretty comprehensive, so that there are plenty of options for ways to analyze, visualize, and manipulate it.
# 

# ---

# ## Day 9 - 6/15/21 - Dashboards
# 
# ### Content
# 
#  * Chapter 14: Dashboards - [reading](chapter-14-dashboards) and <a href='../../_slides/chapter-14-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Network data exercise**
#     * The purpose of this exercise is to familiarize you with some network data, since next week we will be studying just that.  It also gives you another chance to practice `pd.merge()`.
#     * <a href='../../_static/shipping1997.xlsx'>Download this Excel workbook</a> of shipping data among U.S. states in 1997.
#     * Look over all the sheets in the workbook to familiarize yourself with their meaning.
#     * Create a Jupyter notebook that reads all the sheets from the workbook.
#     * Add code that creates a DataFrame just like the shipping sheet, but with each state abbreviation replaced by its full name.
#     * The "adjacent" column in the distances DataFrame should be boolean type; convert it.
#     * Add two columns to the shipping table, one containing the distance between the two states, and the other containing the boolean of whether the two states are adjacent, both taken from the distance table.
#     * Publish the dataset and your notebook with either Deepnote or Colab, your choice.  **Note:** Reading Excel files requires installing the `xlrd` module, which is not present by default in some cloud computing environments.  You may need to run `pip install xlrd` in the terminal, or at the top of the notebook, or place it in a `requirements.txt` file.
#     * Send the link to your project to your instructor.
#  * **Reading**
#     * [Chapter 15: Relations as graphs and network analysis](chapter-15-networks)
# 

# ---

# ## Day 10 - 6/17/21 - Relations, graphs, and networks
# 
# ### Content
# 
#  * Chapter 15: Relations as graphs and network analysis - [reading](chapter-15-networks) and <a href='../../_slides/chapter-15-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Data prep exercise for a music recommendation system**
#     * In class next time we will build a recommender system for songs (that is, given your preferences and a big database of other people's preferences, it will try to match you with new songs you might like).
#     * Visit [this page](https://archive.org/details/thisismyjam-datadump) and read about the data archive, then download it from there in ZIP format.  It is almost 1GB in size, so leave some time for this download!
#     * Unzip the download and find within it three files; we care only about `jams.tsv`.  Place this file in a folder where you can access it with Python and pandas.  It contains every user's "jams" from 2011-2015.
#     * Write some code to load into a pandas Series the full set of *unique* user IDs in that file.  That is, do not include any user more than once in the series.  (This code may be slow to run, because the file is large.)  This step is asking for *just the user IDs,* not any jam or song data.
#     * Use the `sample()` method in pandas Series objects to select a random subset of the users to work with, so that we don't have to deal with the entire jams file, which would take a long time to do computations with.  Include at least 1000 in your sample, to get a sufficient representation of the full dataset.  I chose 2000 in my own work, but later computations will get much slower if you go beyond about 2000.
#     * Write some code to load from the `jams.tsv` DataFrame every jam by all the users in your sample.  There are roughly 15 jams per user on average, so you should end up with 15 times as many results as the number of users you chose (about 15,000 to 30,000).
#     * We need only three columns of the result: user ID, artist, and song title.  Discard all other columns.
#     * To give a song a unique name string, let's combine the artist and song title into a single column.  That is, rather than a column with "Don't Stop Believin'" for song title and "Journey" as artist, create a new column called "song" that contains text like "Don't Stop Believin', by Journey".
#     * Drop the original title and artist columns so that your final jams DataFrame contains just two columns, user and song.
#     * Export that DataFrame to a new CSV file that we will analyze in class.  Call it `jam-sample.csv`.
#     * It should be less than 3MB, so you can email it to your instructor to demonstrate that you have done this prep work.
#  * **Reading**
#     * [Chapter 16: Relations as matrices](chapter-16-matrices)

# ---

# ## Day 11 - 6/22/21 - Relations as matrices
# 
# ### Content
# 
#  * Chapter 15: Relations as matrices - [reading](chapter-16-matrices) and <a href='../../_slides/chapter-16-slides.html'>slides</a>
# 
# ### Due before next class
# 
#  * **Data preparation exercise**
#     * In class next time we will do an introductory machine learning exercise about predicting mortgage approval/denial.
#     * <a href='../../_static/mortgage-testing-data.csv'>Download the training dataset here.</a>  It is a sample from the same mortgage dataset we've used many times.  Recall that its data dictionary is available [online here](https://ffiec.cfpb.gov/documentation/2018/lar-data-fields/).
#     * Load it into pandas and check the data types of the columns.
#     * To make all the data numeric, we will be replacing categorical columns with boolean columns in which false is represented by 0 and true is represented by 1.  This will make it possible to use that data in a numerical model.
#     * Replace the `conforming_loan_limit` column with two boolean columns, one that means "conforming loan limit is C (conforming)" and one that means "conforming loan limit is NC (not conforming)."  Don't forget to use 0/1 instead of False/True.  (There are other values that column may take on, but we will analyze just those two.)
#     * Replace the `derived_sex` column with two boolean columns, one that means "derived sex is Male" and one that means "derived sex is Female."  Don't forget to use 0/1 instead of False/True.  (There are other values that column may take on, but we will analyze just those two.)
#     * The `action_taken` column contains only 1s and 3s.  This is because this dataset was filtered to include only accepted or rejected mortgages (no withdrawals, pre-approvals, etc.).  Replace this column with another boolean column, still using 0/1 for False/True, meaning "application accepted."
#     * The debt-to-income ratio column is categorical instead of numeric.  Make it numeric by replacing each category with a central value in that category.  For instance, the category "20%-<30%" can be replaced with the number 25, the category "43" can be just the number 43, etc.  Let's use 70 for ">60%."
#     * Your newly cleaned data should have all numeric columns.  Export it as a CSV file and bring it with you to class for an in-class activity in Week 12.
#     * To receive credit for having done this preparatory homework, also email the file to your instructor before class on Week 12.
#  * **Reading**
#     * [Chapter 17: Introduction to machine learning](chapter-17-machine-learning)
# 
# (Perhaps more assignments are coming; this section is still incomplete.)
# 

# ---

# ## Day 12 - 6/24/21 - Introduction to machine learning
# 
# ### Content
# 
#  * Chapter 17: Introduction to machine learning - [reading](chapter-17-machine-learning) and <a href='../../_slides/chapter-17-slides.html'>slides</a>
# 
# No more homework this semester!  Use the remaining time to do a great final project!
# 

# ---

# ## Day 13 - 6/29/21 - Thanksgiving break, no class
# 
# No assignments over break, but it would be wise to continue to make progress on the Final Project.
# 

# ---

# ## Day 14 - 7/1/21 - Final Exam Review and Final Project Workshop
# 
# ### Final Exam
# 
# * Based on the review we do in class today, study for the Final Exam.
# 
# ### Final Project
# 
# * Come to class today ready to use half of class to work on your final project in class, and ask questions of the instructor if/when you get stuck on anything.

# In[ ]:




