

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>17. Introduction to Machine Learning &#8212; MA346 Course Notes</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/mystnb.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://nathancarter.github.io/ma346-course-notes/chapter-17-machine-learning.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1. Detailed Course Schedule" href="course-schedule.html" />
    <link rel="prev" title="16. Relations as Matrices" href="chapter-16-matrices.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">


<!-- Opengraph tags -->
<meta property="og:url"         content="https://nathancarter.github.io/ma346-course-notes/chapter-17-machine-learning.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Introduction to Machine Learning" />
<meta property="og:description" content="Introduction to Machine Learning  &lt;a href=&#34;../../_slides/chapter-17-slides.html&#34;&gt;See also the slides that summarize a portion of this content.&lt;/a&gt;  While Bentle" />
<meta property="og:image"       content="https://nathancarter.github.io/ma346-course-notes/_static/logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">MA346 Course Notes</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Notes
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-1-intro-to-data-science.html">
   1. Introduction to Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-2-mathematical-foundations.html">
   2. Mathematical Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-3-jupyter.html">
   3. Jupyter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-4-review-of-python-and-pandas.html">
   4. Review of Python and pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-5-before-and-after.html">
   5. Before and After
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-6-single-table-verbs.html">
   6. Single-Table Verbs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-7-abstraction.html">
   7. Abstraction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-8-version-control.html">
   8. Version Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-9-math-and-stats.html">
   9. Mathematics and Statistics in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-10-visualization.html">
   10. Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-11-processing-rows.html">
   11. Processing the Rows of a DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-12-concat-and-merge.html">
   12. Concatenating and Merging DataFrames
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-13-etl.html">
   13. Miscellaneous Munging Methods (ETL)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-14-dashboards.html">
   14. Dashboards
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-15-networks.html">
   15. Relations as Graphs - Network Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter-16-matrices.html">
   16. Relations as Matrices
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   17. Introduction to Machine Learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="course-schedule.html">
   1. Detailed Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="big-cheat-sheet.html">
   2. Big Cheat Sheet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="anaconda-installation.html">
   3. Anaconda Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vs-code-installation.html">
   4. VS Code for Python Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GB213-review-in-Python.html">
   5. GB213 Review in Python
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter-17-machine-learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-and-unsupervised-learning">
   17.1. Supervised and unsupervised learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#seen-and-unseen-data">
   17.2. Seen and unseen data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-a-mathematical-model">
     17.2.1. What is a mathematical model?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#models-built-on-data">
     17.2.2. Models built on data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting-and-underfitting">
     17.2.3. Overfitting and underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#signal-and-noise">
     17.2.4. Signal and noise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-validation-and-testing">
   17.3. Training, validation, and testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-vs-testing">
     17.3.1. Training vs. testing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-leakage">
     17.3.2. Data leakage
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validation">
     17.3.3. Validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   17.4. Logistic Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-vs-regression">
     17.4.1. Classification vs. regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#medical-example">
     17.4.2. Medical example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression-in-scikit-learn">
     17.4.3. Logistic regression in scikit-learn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-coefficients">
     17.4.4. Model coefficients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-success">
   17.5. Measuring success
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#categorical-input-variables">
   17.6. Categorical input variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overfitting-and-underfitting-in-this-example">
   17.7. Overfitting and underfitting in this example
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-machine-learning">
<h1><span class="section-number">17. </span>Introduction to Machine Learning<a class="headerlink" href="#introduction-to-machine-learning" title="Permalink to this headline">¶</a></h1>
<p><a href="../../_slides/chapter-17-slides.html">See also the slides that summarize a portion of this content.</a></p>
<p>While Bentley University does not currently have an undergraduate course in Machine Learning, there are several related courses currently available.  MA347 (Data Mining) covers topics related to machine learning, but not exactly the same; both are advanced math and stats implemented in a programming environment, but with different focuses.</p>
<p>Machine learning is also closely connected to mathematical modeling, and we have statistics courses that cover modeling, especially MA252 (Regression Analysis), MA315 (Mathematical Modeling with VBA in Excel), and MA380 (Introduction to Generalized Linear Models and Survival Analysis in Business).  And if you are planning to stay at Bentley for graduate school, there is a machine learning course at the graduate level, MA707 (Introduction to Machine Learning), and a somewhat related course CS733 (AI Techniques and Applications).</p>
<p>Today’s notes are a small preview of the kind of material that appears in a machine learning course.</p>
<div class="section" id="supervised-and-unsupervised-learning">
<h2><span class="section-number">17.1. </span>Supervised and unsupervised learning<a class="headerlink" href="#supervised-and-unsupervised-learning" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-primary admonition">
<p class="admonition-title">Big Picture - Supervised vs. unsupervised machine learning</p>
<p>Machine learning is broken into two categories, supervised and unsupervised.  The definitions for these are below.</p>
</div>
<p><strong>Supervised learning</strong> provides to the computer a dataset of inputs and their corresponding outputs, and asks the computer to learn something about the relationships between the inputs and the outputs.  One of the most commonly used examples is to provide small photographs of handwritten digits as the inputs (like those shown below, <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database#/media/File:MnistExamples.png">from this source</a>) and make the corresponding outputs the integer represented.  For instance, for the top left input shown below, the output would be the integer 0.</p>
<p><img alt="A grid of handwritten numerical digits shown in grayscale" src="_images/MnistExamples.png" /></p>
<p>This is called supervised learning because the data scientist is providing the outputs that the computer <em>should</em> be giving for each input.  It is as if the data scientist is looking over the computer’s shoulder, teaching it what kinds of outputs it should learn to create.  A mathematical model trained on a large enough set of inputs and outputs like those can learn to recognize handwritten digits with a high degree of accuracy.  The most common technique of doing so is with neural networks and deep learning, topics covered in MA707.</p>
<p><strong>Unsupervised learning</strong> provides to the computer a dataset, but does not break it into input-output pairs.  Rather, the data scientist asks the computer to detect some kind of structure within the data.  One example of this is cluster analysis, covered in MA347, but you saw another example in <a class="reference internal" href="chapter-16-matrices.html"><span class="doc std std-doc">the Chapter 16 notes</span></a>.  When we used SVD to approximate a network, thus revealing more of its latent structure than the precise data itself revealed, we were having the computer do unsupervised learning.  Another example of unsupervised learning is principal components analysis (PCA), covered in many statistics courses.</p>
<p>Today, we will focus on supervised learning.  For this reason, when we look at data, we will designate one column as the output that we want the computer to learn to predict from all the other columns as inputs.  The terminology for inputs and output varies:</p>
<ul class="simple">
<li><p>Computer science typically speaks of the <em>inputs</em> and the <em>output.</em></p></li>
<li><p>Machine learning typically speaks of the <em>features</em> and the <em>target.</em></p></li>
<li><p>Statistics typically speaks of the <em>predictors</em> and the <em>respoonse.</em></p></li>
</ul>
<p>I may use any of these terms in this chapter and in class; you should become familiar with the fact that they are synonyms for one another.  Although mathematics has its own terms for inputs and outputs (like domain and range) these are not used to refer to specific columns of a dataset, so I don’t include them on the list above.  <strong>Most of machine learning is supervised, and we will focus on supervised learning exclusively in this chapter.</strong></p>
</div>
<div class="section" id="seen-and-unseen-data">
<h2><span class="section-number">17.2. </span>Seen and unseen data<a class="headerlink" href="#seen-and-unseen-data" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-primary admonition">
<p class="admonition-title">Big Picture - A central issue: overfitting vs. underfitting</p>
<p>Probably the most significant concern in mathematical modeling in general (and machine learning in particular) is <em>overfitting</em> vs. <em>underfitting</em> for a mathematical model, sometimes also called <em>bias</em> vs. <em>variance.</em>  We explore its meaning in this section, and we will find that it is intimately tied up with how mathematical models perform on unseen data.</p>
</div>
<div class="section" id="what-is-a-mathematical-model">
<h3><span class="section-number">17.2.1. </span>What is a mathematical model?<a class="headerlink" href="#what-is-a-mathematical-model" title="Permalink to this headline">¶</a></h3>
<p>Since overfitting and underfitting are concepts that apply to mathematical models, let’s ensure that we have a common definition for a mathematical model.  Just as a model airplane is an imitation of a real airplane, and just as the <a class="reference external" href="https://unausa.org/model-un/">Model UN</a> is an imitation of the actual United Nations, a mathematical model is an imitation of reality.  But while a model airplane is built of plastic and the Model UN is built of students, a mathematical model is built of mathematics, such as equations, algorithms, or formulas.  Like any model, a mathematical model does not perfectly represent the real thing, but we aim to make models that are good enough to be useful.</p>
<p>A mathematical model that you’re probably familiar with is the position of a falling object over time, introduced in every introductory physics class.  It’s written as <span class="math notranslate nohighlight">\(s(t)=\frac12gt^2+v_0t+s_0\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> is time, <span class="math notranslate nohighlight">\(g\)</span> is the acceleration due to gravity, <span class="math notranslate nohighlight">\(v_0\)</span> is the initial velocity, and <span class="math notranslate nohighlight">\(s_0\)</span> the initial position.  This is very accurate for experiments that happen in the small laboratories we encounter in physics classes, but it becomes inaccurate if we consider, for example, a skydiver.  Even before deploying a parachute, the person’s descent is significantly impacted by air resistance, and dramatically more so after deploying the parachute, but the simple model just given doesn’t include air resistance.  So it’s a good model, but not a perfect model.  All mathematical models of real world phenomena are imperfect; we just try to make good ones.</p>
</div>
<div class="section" id="models-built-on-data">
<h3><span class="section-number">17.2.2. </span>Models built on data<a class="headerlink" href="#models-built-on-data" title="Permalink to this headline">¶</a></h3>
<p>Physicists, however, have it easy, in the sense that physical phenomena tend to follow simple mathematical laws.  In fact, the rule for falling objects just given in the previous paragraph is so simple that students who have completed only Algebra I can understand it; no advanced degree in mathematics required!  Such simple patterns are easy to spot in experimental data.</p>
<p>Data science, however, is typically applied to more complex systems, such as economies, markets, sports, medicine, and so on, where simple patterns aren’t always the rule.  In fact, when we see a dataset and try to create a mathematical model (say, a formula) that describes it well, it won’t always be obvious when we’ve done a good job.  A physicist can often go and get more data through an experiment, but a data scientist may not be able to do so; sometimes one dataset is all you have.  Is it enough data to validate when we’ve made a good model?</p>
<p>That raises the question:  <em>What is a good model?</em>  The answer is that a good model is one that is reliable enough to be useful, often for prediction.  For example, if we write a formula that predicts the expected increase in sales that will come from a given amount of marketing spending in a certain channel, we’ll want to use that to consider possible future scenarios when making strategic decisions.  It’s a good model if it’s reliable enough to make decent predictions about the future (with some uncertainty of course).</p>
<p>In that example, the formula for sales based on marketing spending would have been built from some past experience (<em>seen data,</em> that is, data we’ve actually seen, in the past).  But we’re using it to predict something that could happen in the future, asking “what if we spent this much?”  We’re hoping the model will still be good on <em>unseen data,</em> that is, inputs to the model that we haven’t yet seen happen.</p>
<p>Consider another example.  When researchers work on developing self-driving cars, they gather lots of data from cameras and sensors in actual vehicles, and train their algorithms to make the correct decisions in all of those situations.  But of course, if self-driving cars are ever to succeed, the models the researchers create will need to work correctly on new, unseen data as well–that is, the new camera and sensor inputs the system experiences when it’s actually driving a car around the real world.  The model will be built using known/seen data, but it has to work well also on unkown, or not-yet-seen, data.</p>
</div>
<div class="section" id="overfitting-and-underfitting">
<h3><span class="section-number">17.2.3. </span>Overfitting and underfitting<a class="headerlink" href="#overfitting-and-underfitting" title="Permalink to this headline">¶</a></h3>
<p>This brings us to the big dilemma introduced above.  There are two big mistakes that a data scientist can make when fitting a model to existing data.</p>
<ul class="simple">
<li><p>The data scientist could make a model that tailors itself to every detail of the known data precisely.</p>
<ul>
<li><p>This is called <em>overfitting,</em> because the model is too much dependent on the peculiarities of that one dataset, and so it won’t behave well on new data.</p></li>
<li><p>It typically happens if the model is too complex and/or customized to the data.</p></li>
<li><p>It is also called <em>variance,</em> because the model follows too much the tiny variations of the dataset, rather than just its underlying structure.</p></li>
</ul>
</li>
<li><p>The data scientist could make a model that captures only very simple characteristics of the known data and ignores some important details.</p>
<ul>
<li><p>This is called <em>underfitting,</em> because the model is too simple, and missed some signals that the data scientist could have learned from the known data.</p></li>
<li><p>It typically happens if the model is not complex enough.</p></li>
<li><p>It is also called <em>bias,</em> because just as a social bias may pigeonhole a complex person into a simple stereotype, making the decision to use too simple a mathematical model also pigeonholes a complex problem into a simple stereotype, and limits the values of the results.</p></li>
</ul>
</li>
</ul>
<p>So we have a spectrum, from simple models to complex models, and there’s some happy medium in between.  Finding that happy medium is the job of a mathematical modeler.</p>
<p>This issue is intimiately related to the common terms of signal and noise, so it’s worth exploring this important issue from that viewpoint as well.</p>
</div>
<div class="section" id="signal-and-noise">
<h3><span class="section-number">17.2.4. </span>Signal and noise<a class="headerlink" href="#signal-and-noise" title="Permalink to this headline">¶</a></h3>
<p>Surely, we’ve all seen a movie in which something like this happens:  An astronaut is trying to radio back to earth, but the voice they’re hearing is mostly static and crackling, with only some glimpses of actual words coming through.  The words are the <em>signal</em> the astronaut is hoping to hear and the crackling static is the <em>noise</em> on the line preventing the signal from coming through clearly.  Although these are terms with roots in engineering and the hard sciences, they are common metaphors in statistics and data work as well.  One famous modern example of their use in that sphere is the title of Nate Silver’s popular and award-winning 2012 book, <a class="reference external" href="https://www.amazon.com/Signal-Noise-Many-Predictions-Fail-but/dp/0143125087">The Signal and the Noise</a>.  Let’s use the pictures below to see why Silver used these terms to talk about statistics.</p>
<p><img alt="Three images, on the left, a blue parabola, in the center, a red curve that wiggles a lot, and on the right, in black, the sum of the two" src="_images/signal-and-noise.png" /></p>
<p>Let’s imagine for a moment a simple scenario with one input variable and one output variable, such as the example earlier of marketing spend in a particular channel vs. expected sales increase.</p>
<ol class="simple">
<li><p>If we could see with perfect clarity how the world worked, we would know exactly how customers respond to our marketing spending.  This omniscient knowledge about marketing nobody has, but we can imagine that it exists somewhere, even if no one knows it (except God).  That knowledge is the signal that we are trying to detect.  It’s shown on the left above.  (That curve doesn’t necessarily have anything to do with marketing; it’s just an example curve.)</p></li>
<li><p>Whenever we try to gather data about the phenomenon we care about, inevitably some problems mess things up.  We might make mistakes when measuring or recording data.  Some of our data might be recorded at times that are special (like a holiday weekend) that make them not representative of the whole picture.  And other variables might be influencing our data that we didn’t measure, such as the weather or other companies’ marketing campaigns.  All of this creates fluctuations we call noise, as shown in the middle.</p></li>
<li><p>What we actually measure when we gather data is the combination of these two things, as shown on the right, above.  Of course, when we get data, we see only that final graph, the signal plus the noise together, and we don’t know how to separate them.</p></li>
</ol>
<p>Not knowing that the original signal was parabolic, we might make either of two mistakes.  First, we might make a model that is too simple, an underfit model, such as a linear one.</p>
<p><img alt="A linear regression line drawn through the data from the right of the previous figure" src="_images/signal-and-noise-2.png" /></p>
<p>You can see that the model is a bit higher than the center of the data on each end, and a bit lower than the center of the data in the middle.  This is because the model is missing some key feature of the data, its slight downward curvature.  The model is <em>underfit;</em> it should be more fit to the unique characteristics this data is showing.</p>
<p>Second, we might make a model that is too complex, an overfit model, such as a high-degree polynomial model.</p>
<p><img alt="A polynomial model with many ups and downs drawn through the same data as in the previous figure" src="_images/signal-and-noise-3.png" /></p>
<p>This is a particularly easy mistake to make in Excel, where you can use the options in the trendline dialog box to choose any polynomial model you like, and it’s tempting to crank up the polynomial degree and watch the measurement of goodness of fit increase!  But that measure is telling you only how well the model fits the data you have, not any unseen data.  That difference is the core of what overfitting means.  The model is overfit to known data, and thus probably generalizes poorly to unseen data.</p>
<p>Polynomial models are especially problematic in this area, because all polynomials (other than linear ones) diverge rapidly towards <span class="math notranslate nohighlight">\(\pm\infty\)</span> in both directions, thus making them highly useless for prediction if given an input outside the range of the data on which the model was fit.</p>
<p>The happy medium between these two mistakes, in this case, is a quadratic model, because in this example, I made the signal a simple quadratic function.  Of course, in the real world, signals of many types can occur, and their exact nature is not known from the data alone.</p>
<p><img alt="A quadratic function drawn through the data from the previous figure" src="_images/signal-and-noise-4.png" /></p>
<p>Although this quadratic model may not exactly match the quadratic function that is the signal, it is the closest we can come based on the data we observed.</p>
<p>Now we know what the problems are.  How do we go about avoiding underfitting or overfitting?  Machine learning (and mathematical modeling in general) have developed some best practices for doing just that.</p>
</div>
</div>
<div class="section" id="training-validation-and-testing">
<h2><span class="section-number">17.3. </span>Training, validation, and testing<a class="headerlink" href="#training-validation-and-testing" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-primary admonition">
<p class="admonition-title">Big Picture - Why we split data into train and test sets</p>
<p>Recall that the key question we’re trying to answer is, “How do I make a model that works well on unseen data?”  Or more precisely, “How do I make a model that works well on data that wasn’t used to create the model?”</p>
<p>The solution is actually rather simple:  When given a dataset, split it into two parts, one you will use to create your model, and the other that you will use as “unseen data,” on which to test your model.  The details are actually slightly more intricate than that simple answer, but that’s the heart of it.</p>
</div>
<div class="section" id="training-vs-testing">
<h3><span class="section-number">17.3.1. </span>Training vs. testing<a class="headerlink" href="#training-vs-testing" title="Permalink to this headline">¶</a></h3>
<p>If we take the advice above into account, the process of mathematical modeling would then proceed like this:</p>
<ol class="simple">
<li><p>We get a dataset <code class="docutils literal notranslate"><span class="pre">df</span></code> that we’re going to use to build a model.</p></li>
<li><p>We split the data into two parts, a larger part <code class="docutils literal notranslate"><span class="pre">df_train</span></code> that we’ll use for “training” (creating the model) and a smaller part <code class="docutils literal notranslate"><span class="pre">df_test</span></code> that we’ll use for testing the model after it’s been created.</p>
<ul class="simple">
<li><p>Since <code class="docutils literal notranslate"><span class="pre">df_test</span></code> isn’t used to create the model, it’s “unseen data” from the model’s point of view, and can give us a hint on how the model will perform on data that’s entirely outside of <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p></li>
<li><p>Typically, <code class="docutils literal notranslate"><span class="pre">df_train</span></code> is a random sample of about 70%-80% of <code class="docutils literal notranslate"><span class="pre">df</span></code>, and <code class="docutils literal notranslate"><span class="pre">df_test</span></code> is the other 20%-30%.</p></li>
</ul>
</li>
<li><p>We choose which model we want to use (such as linear regression, for example) and fit the model to <code class="docutils literal notranslate"><span class="pre">df_train</span></code> only.</p>
<ul class="simple">
<li><p>This is called the <em>training</em> phase; what statisticians call “fitting a model,” machine learning people call “training the model.”</p></li>
</ul>
</li>
<li><p>We use the model to predict outputs for each input in <code class="docutils literal notranslate"><span class="pre">df_test</span></code> and compare them to the known outputs in <code class="docutils literal notranslate"><span class="pre">df_test</span></code>, and see how well the model does.</p>
<ul class="simple">
<li><p>For example, you might compute the distribution of percent errors, and see if they’re within the tolerance you can accept in your business application.</p></li>
<li><p>This is called the <em>testing</em> phase.</p></li>
</ul>
</li>
<li><p>If the model seems acceptable, you would then proceed to re-fit the same model on the entire dataset <code class="docutils literal notranslate"><span class="pre">df</span></code> before you use it for predictions, because more data tends to improve model quality.</p></li>
</ol>
<p>It is easy to split a DataFrame’s rows into two different sets like this with random sampling.  Use code like the following.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create some fake data to use for demonstrating the technique:</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span> <span class="s1">&#39;Totally&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;Fake&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;Data&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="p">}</span> <span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Totally</th>
      <th>Fake</th>
      <th>Data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.111111</td>
      <td>3.111111</td>
      <td>5.111111</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.222222</td>
      <td>3.222222</td>
      <td>5.222222</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.333333</td>
      <td>3.333333</td>
      <td>5.333333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.444444</td>
      <td>3.444444</td>
      <td>5.444444</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.555556</td>
      <td>3.555556</td>
      <td>5.555556</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.666667</td>
      <td>3.666667</td>
      <td>5.666667</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.777778</td>
      <td>3.777778</td>
      <td>5.777778</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.888889</td>
      <td>3.888889</td>
      <td>5.888889</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2.000000</td>
      <td>4.000000</td>
      <td>6.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Choose an approximately 80% subset:</span>
<span class="c1"># (In this case, 8 is 80% of the rows.)</span>
<span class="n">rows_for_training</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="kc">False</span> <span class="p">)</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span> <span class="n">rows_for_training</span> <span class="p">)</span>
<span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">training</span><span class="p">]</span>
<span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">training</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see the resulting split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Totally</th>
      <th>Fake</th>
      <th>Data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1.111111</td>
      <td>3.111111</td>
      <td>5.111111</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.222222</td>
      <td>3.222222</td>
      <td>5.222222</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.444444</td>
      <td>3.444444</td>
      <td>5.444444</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.555556</td>
      <td>3.555556</td>
      <td>5.555556</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1.666667</td>
      <td>3.666667</td>
      <td>5.666667</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1.777778</td>
      <td>3.777778</td>
      <td>5.777778</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1.888889</td>
      <td>3.888889</td>
      <td>5.888889</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2.000000</td>
      <td>4.000000</td>
      <td>6.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Totally</th>
      <th>Fake</th>
      <th>Data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.333333</td>
      <td>3.333333</td>
      <td>5.333333</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="data-leakage">
<h3><span class="section-number">17.3.2. </span>Data leakage<a class="headerlink" href="#data-leakage" title="Permalink to this headline">¶</a></h3>
<p>It is is essential, in the above five-step process, not to touch (or typically even look at) the testing data (in <code class="docutils literal notranslate"><span class="pre">df_test</span></code>) until the testing phase.  It is also essential not to repeat back to step 1, 2, or 3 once you’ve reached step 4.  Otherwise <code class="docutils literal notranslate"><span class="pre">df_test</span></code> no longer represents unseen data.  (Like that embarrassing social media post, you can’t unsee it.)  In fact, in machine learning competitions, the group running the competition will typically split the data into training and testing sets before the competition, and distribute only the training set to competitors, leaving the testing set secret, to be used for judging the winner.  It’s truly unseen data!</p>
<p>If a data scientist even looks at the test data or does summary statistics about it, this information can influence how they do the modeling process on training data.  This error is called <em>data leakage,</em> because some aspects of the test data have leaked out of where they’re supposed to be safely contained at the end of the whole process, and have contaminated the beginning of the process instead.  The five-step process given above is designed, in part, to eliminate data leakage.</p>
</div>
<div class="section" id="validation">
<h3><span class="section-number">17.3.3. </span>Validation<a class="headerlink" href="#validation" title="Permalink to this headline">¶</a></h3>
<p>But this restriction on seeing <code class="docutils literal notranslate"><span class="pre">df_test</span></code> only once introduces a significant drawback.  What if you have several different models you’d like to try, and you’re not sure which one will work best on unseen data?  How can we compare multiple models if we can test only one?  The question is even more complex if the model comes with parameters that a data scientist is supposed to choose (so-called hyperparameters), which may require some iterative experimentation.</p>
<p>The answer to this problem involves introducing a new phase, called <em>validation,</em> in between training and testing, and creating a three-way data split.  Perhaps you’ve heard of the technique of <em>cross-validation,</em> one particular way to do the validation step.  In this chapter, since we are just doing a quick introduction to the machine learning process, we will not dive deeply into the validation phase, but will just keep the five-step process shown above, which uses only a train/test split of the data.</p>
</div>
</div>
<div class="section" id="logistic-regression">
<h2><span class="section-number">17.4. </span>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h2>
<p>Machine learning is an area of statistics and computer science that includes many types of advanced models, such as support vector machines, neural networks, decision trees, random forests, and other ensemble methods.  We will see in this small, introductory chapter just one new modeling method, logistic regression.  But we will use it as a way to see several aspects of the way machine learning is done in practice, including the train/test data split discussed above.</p>
<div class="section" id="classification-vs-regression">
<h3><span class="section-number">17.4.1. </span>Classification vs. regression<a class="headerlink" href="#classification-vs-regression" title="Permalink to this headline">¶</a></h3>
<p>The particular machine learning task we’ll cover as an example in this chapter uses a technique called logistic regression.  This technique is covered in detail in MA347 and MA380, but we will do just a small preview here.  The key difference between logistic regression and linear regression is one of output type:</p>
<ul class="simple">
<li><p>Linear regression creates a model whose output type is real numbers.</p></li>
<li><p>Logistic regression creates a model whose output type is boolean, with values 0 and 1.</p></li>
</ul>
<p>(Technically, logistic regression models create outputs anywhere in the interval <span class="math notranslate nohighlight">\((0,1)\)</span>, not including either end, and we round up/down from the center to convert them to boolean outputs.)</p>
<p>Machine learning tasks are often sorted broadly into two categories, <em>classification</em> and <em>regression</em>.  Models that output boolean values (or any small number of choices, not necessarily two) are called classification models, and models that output numerical values are called regression models.  (This is unfortunate, because logistic regression is used for classification.  I don’t pick the names.)  We are going to study a binary classification problem below, and so we want a model that outputs one of two values, 0 or 1.  Logistic regression is a natural choice.</p>
<p>If you take MA347 or MA380, you will learn the exact transformation of the inputs and outputs that make logistic regression possible.  But for our purposes here, we will just use Python code that handles them for us.  The essentials are that we provide any set of numeric variables as input and we get boolean values (zeros and ones) as model output.</p>
</div>
<div class="section" id="medical-example">
<h3><span class="section-number">17.4.2. </span>Medical example<a class="headerlink" href="#medical-example" title="Permalink to this headline">¶</a></h3>
<p>Let’s make this concrete with an example.  Assume we’ve measured three important health variables about ten patients in a study and then given them all an experimental drug.  We then measured whether they responded well or not to the drug (0 meaning no and 1 meaning yes).  We’d like to try to predict, from their initial three health variables, whether they will respond well to the drug, so we know which new patients might benefit.  We will use fabricated data, partly because medical data is private and partly beacuse it will be nice to have a small example from which to learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_drug_response</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="p">{</span>
    <span class="s1">&#39;Height (in)&#39;</span>     <span class="p">:</span> <span class="p">[</span>  <span class="mi">72</span><span class="p">,</span>  <span class="mi">63</span><span class="p">,</span>  <span class="mi">60</span><span class="p">,</span>  <span class="mi">69</span><span class="p">,</span>  <span class="mi">59</span><span class="p">,</span>  <span class="mi">74</span><span class="p">,</span>  <span class="mi">63</span><span class="p">,</span>  <span class="mi">67</span><span class="p">,</span>  <span class="mi">60</span><span class="p">,</span>  <span class="mi">64</span> <span class="p">],</span>
    <span class="s1">&#39;Weight (lb)&#39;</span>     <span class="p">:</span> <span class="p">[</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">191</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">205</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span> <span class="mi">139</span><span class="p">,</span> <span class="mi">184</span><span class="p">,</span> <span class="mi">230</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span> <span class="mi">169</span> <span class="p">],</span>
    <span class="s1">&#39;Systolic (mmHg)&#39;</span> <span class="p">:</span> <span class="p">[</span>  <span class="mi">90</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span>  <span class="mi">85</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">145</span><span class="p">,</span>  <span class="mi">99</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span>  <span class="mi">89</span> <span class="p">],</span>
    <span class="s1">&#39;Response&#39;</span>        <span class="p">:</span> <span class="p">[</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">1</span> <span class="p">]</span>
<span class="p">}</span> <span class="p">)</span>
<span class="n">df_drug_response</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height (in)</th>
      <th>Weight (lb)</th>
      <th>Systolic (mmHg)</th>
      <th>Response</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>72</td>
      <td>150</td>
      <td>90</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>191</td>
      <td>105</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>60</td>
      <td>112</td>
      <td>85</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>69</td>
      <td>205</td>
      <td>130</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>136</td>
      <td>107</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>74</td>
      <td>139</td>
      <td>117</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>63</td>
      <td>184</td>
      <td>145</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>67</td>
      <td>230</td>
      <td>99</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>60</td>
      <td>198</td>
      <td>109</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>64</td>
      <td>169</td>
      <td>89</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let us assume that this data is the training dataset, and the test dataset has already been split out and saved in a separate file, where we cannot yet see it.  We will create a model on this dataset, and then later evaluate how well it behaves on new data.</p>
<p>When we apply logistic regression to this dataset, we will want to make it clear which columns are to be seen as inputs (or features or predictors) and which is to be seen as the output (or target or response).  To facilitate this, let’s store them in different variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[[</span><span class="s1">&#39;Height (in)&#39;</span><span class="p">,</span><span class="s1">&#39;Weight (lb)&#39;</span><span class="p">,</span><span class="s1">&#39;Systolic (mmHg)&#39;</span><span class="p">]]</span>
<span class="n">response</span>   <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="logistic-regression-in-scikit-learn">
<h3><span class="section-number">17.4.3. </span>Logistic regression in scikit-learn<a class="headerlink" href="#logistic-regression-in-scikit-learn" title="Permalink to this headline">¶</a></h3>
<p>A very popular machine learning toolit is called scikit-learn, and is distributed as the Python module <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.  If your Python installation came from Anaconda, you already have <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> installed.  We can use the logistic regression tools built into scikit-learn to create a logistic regression model that will use the first three columns above as inputs from which it should predict the final column as the output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the module</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Create a model and fit it to the data</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">response</span> <span class="p">)</span>

<span class="c1"># Let&#39;s see how close it came.</span>
<span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">predictors</span> <span class="p">)</span>
<span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Correct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span>
<span class="n">df_drug_response</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height (in)</th>
      <th>Weight (lb)</th>
      <th>Systolic (mmHg)</th>
      <th>Response</th>
      <th>Prediction</th>
      <th>Correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>72</td>
      <td>150</td>
      <td>90</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>191</td>
      <td>105</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>60</td>
      <td>112</td>
      <td>85</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>69</td>
      <td>205</td>
      <td>130</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>136</td>
      <td>107</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>74</td>
      <td>139</td>
      <td>117</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>6</th>
      <td>63</td>
      <td>184</td>
      <td>145</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>67</td>
      <td>230</td>
      <td>99</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>8</th>
      <td>60</td>
      <td>198</td>
      <td>109</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>9</th>
      <td>64</td>
      <td>169</td>
      <td>89</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Correct&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_drug_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.7
</pre></div>
</div>
</div>
</div>
<p>This model achieved a 70% correct prediction rate on this data.  Of course, this is a small dataset and is completely fabricated, so this doesn’t mean anything in the real world.  But the purpose is to show you that a relatively small amount of code can set up and use logistic regression.  We will use it for a more interesting example in class.</p>
</div>
<div class="section" id="model-coefficients">
<h3><span class="section-number">17.4.4. </span>Model coefficients<a class="headerlink" href="#model-coefficients" title="Permalink to this headline">¶</a></h3>
<p>But there is still more we can learn here.  Just like linear regression, logistic regression also computes the best coefficient for each variable as part of the model-fitting process.  In linear regression, the resulting model is just the combination of those coefficients with the variables, <span class="math notranslate nohighlight">\(\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_nx_n\)</span>.  In logistic regression, that same formula is then composed with the logistic curve to fit the result into the interval <span class="math notranslate nohighlight">\((0,1)\)</span>, but the coefficients can still tell us which variables were the most important.</p>
<p>Right now, however, our model is fit using predictors that have very different scales.  Height is a two-digit number, weight is a three-digit number, and blood pressure varies in between.  So the coefficients, which must interact with these different units, are not currently comparable.  It is therefore common to create a standardized copy of the predictors and re-fit the model to it, just for comparing coefficients, because then they are all on the same scale.  Standardization is the process of subtracting the mean of a sample and dividing by its standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">standardized</span> <span class="o">=</span> <span class="p">(</span> <span class="n">predictors</span> <span class="o">-</span> <span class="n">predictors</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="p">)</span> <span class="o">/</span> <span class="n">predictors</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">standardized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height (in)</th>
      <th>Weight (lb)</th>
      <th>Systolic (mmHg)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.322744</td>
      <td>-0.583434</td>
      <td>-0.927831</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.402574</td>
      <td>0.534360</td>
      <td>-0.137066</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.977681</td>
      <td>-1.619438</td>
      <td>-1.191419</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.747638</td>
      <td>0.916046</td>
      <td>1.180875</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.169383</td>
      <td>-0.965120</td>
      <td>-0.031631</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.706149</td>
      <td>-0.883330</td>
      <td>0.495546</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-0.402574</td>
      <td>0.343517</td>
      <td>1.971640</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.364234</td>
      <td>1.597627</td>
      <td>-0.453372</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.977681</td>
      <td>0.725203</td>
      <td>0.073805</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-0.210872</td>
      <td>-0.065432</td>
      <td>-0.980548</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">standardized_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">standardized_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">response</span> <span class="p">)</span>
<span class="n">coefficients</span> <span class="o">=</span> <span class="n">standardized_model</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">predictors</span><span class="o">.</span><span class="n">columns</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>Height (in)       -0.170322
Weight (lb)       -0.013302
Systolic (mmHg)    0.062280
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Here we can see that height and weight negatively impacted the drug response and blood pressure positively impacted it.  The magnitude of each variable (in absolute value) shows which variables are more important than others.  A higher absolute value for the variable’s coefficient means it is more important.</p>
<p>This is a rather simple way to compare the importance of variables, and classes like MA252 and MA347 will cover more statistically sophisticated methods.</p>
<p>So the good news is that fitting a logistic model to data is just a few lines of Python code!  But there are several additional details that it will be helpful to know about the context in which we apply logistic regression.  We cover each of those details in the remaining sections of this chapter.</p>
</div>
</div>
<div class="section" id="measuring-success">
<h2><span class="section-number">17.5. </span>Measuring success<a class="headerlink" href="#measuring-success" title="Permalink to this headline">¶</a></h2>
<p>In the example above, we saw a 70% correct prediction rate on our training dataset.  But machine learning practitioners have several ways of measuring the quality of a classification model.  For instance, in some cases, a false positive is better than a false negative.  You don’t mind if the computer system that works for your credit card company texts you after your legitimate purchase and asks, “Was this you?”  It had a false positive for a fraud prediction, checked it out with you, and you said “No problem.”  So a false positive is no big deal.  But a false negative (undetected fraud) is much worse.  So a classification model for credit card fraud should be judged more on its false negative rate than on its false positive rate.  Which measurement is best varies by application domain.</p>
<p>Two common measurements of binary classification accuracy are <em>precision</em> and <em>recall.</em>  Let’s make the following definitions.</p>
<ul class="simple">
<li><p>Use <span class="math notranslate nohighlight">\(TP\)</span> to stand for the number of true positives among our model’s predictions.  (In the example above, <span class="math notranslate nohighlight">\(TP=6\)</span>, for the six rows 1, 4, 5, 6, 8, and 9.</p></li>
<li><p>Similarly, let <span class="math notranslate nohighlight">\(TN\)</span>, <span class="math notranslate nohighlight">\(FP\)</span>, and <span class="math notranslate nohighlight">\(FN\)</span> stand for true negatives, false positives, and false negatives, respectively.  (Above, we had <span class="math notranslate nohighlight">\(TN=2\)</span>, <span class="math notranslate nohighlight">\(FP=2\)</span>, and <span class="math notranslate nohighlight">\(FN=0\)</span>.)</p></li>
<li><p>We define the classifier’s <strong>precision</strong> to be <span class="math notranslate nohighlight">\(\frac{TP}{TP+FP}\)</span>.  This answers the question:  If the test said “positive,” what are the odds that it’s a true positive?  This is the measure that a patient who just got a positive diagnosis cares about.  What are the odds it’s real?</p></li>
<li><p>We define the classifier’s <strong>recall</strong> to be <span class="math notranslate nohighlight">\(\frac{TP}{TP+FN}\)</span>.  This answers the question:  If the reality is “positive,” what are the odds the test will detect that?  This is the measure that the credit card company cares about.  What percentage of fraud does our system catch?</p></li>
</ul>
<p>Let’s see how to code these measurements in Python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># True positive means the answer and the prediction were positive.</span>
<span class="n">TP</span> <span class="o">=</span> <span class="p">(</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="c1"># Similarly for the other three.</span>
<span class="n">TN</span> <span class="o">=</span> <span class="p">(</span> <span class="o">~</span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">FP</span> <span class="o">=</span> <span class="p">(</span> <span class="o">~</span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span> <span class="o">&amp;</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">FN</span> <span class="o">=</span> <span class="p">(</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Response&#39;</span><span class="p">]</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Prediction&#39;</span><span class="p">]</span> <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Precision and recall are defined using the formulas above.</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span> <span class="p">)</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(0.7142857142857143, 0.8333333333333334)
</pre></div>
</div>
</div>
</div>
<p>In many cases, however, both precision and recall matter.  A common way to combine them is in a score called the <span class="math notranslate nohighlight">\(F_1\)</span> score, which combines precision and recall using a formula called the geometric mean.</p>
<div class="math notranslate nohighlight">
\[F_1=\frac{2\times\text{precision}\times\text{recall}}{\text{precision}+\text{recall}}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">F1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span> <span class="o">/</span> <span class="p">(</span> <span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Just as a higher score is better for both precision and recall, a higher score is also better for <span class="math notranslate nohighlight">\(F_1\)</span>.  We can use this measure to compare models, prioritizing a balance of both precision and recall.</p>
</div>
<div class="section" id="categorical-input-variables">
<h2><span class="section-number">17.6. </span>Categorical input variables<a class="headerlink" href="#categorical-input-variables" title="Permalink to this headline">¶</a></h2>
<p>Often we have input variables that are not numeric; in the medical example above, we might also have a patient’s sex or race, and want to know if those impact whether they will respond well to the drug.  Those data are not numeric; they are categorical.  But we can make them numeric using any of several common techniques.</p>
<p>Let’s say we had patient race, and there were several categories, including Black, White, Latino, Indian, Asian, and Other.  I will add data of this type to the original data we saw above.  Of course, this, too, is fictitious data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Asian&#39;</span><span class="p">,</span><span class="s1">&#39;Black&#39;</span><span class="p">,</span><span class="s1">&#39;Black&#39;</span><span class="p">,</span><span class="s1">&#39;Latino&#39;</span><span class="p">,</span><span class="s1">&#39;White&#39;</span><span class="p">,</span><span class="s1">&#39;White&#39;</span><span class="p">,</span><span class="s1">&#39;Indian&#39;</span><span class="p">,</span><span class="s1">&#39;White&#39;</span><span class="p">,</span><span class="s1">&#39;Asian&#39;</span><span class="p">,</span><span class="s1">&#39;Latino&#39;</span><span class="p">]</span>
<span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span> <span class="s1">&#39;category&#39;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Suppose that the medical professionals believe, from past studies in this area, that Black and Indian patients might respond differently to the drug, but everyone else should be similar to one another.  We can therefore convert this categorical variable into two boolean variables, one answering the question, “Is the patient Black?” and the other answering the question, “Is the patient Indian?”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Black&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Black&#39;</span>
<span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Indian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Indian&#39;</span>
<span class="n">df_drug_response</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height (in)</th>
      <th>Weight (lb)</th>
      <th>Systolic (mmHg)</th>
      <th>Response</th>
      <th>Prediction</th>
      <th>Correct</th>
      <th>Race</th>
      <th>Race=Black</th>
      <th>Race=Indian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>72</td>
      <td>150</td>
      <td>90</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
      <td>Asian</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>191</td>
      <td>105</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Black</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>60</td>
      <td>112</td>
      <td>85</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
      <td>Black</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>69</td>
      <td>205</td>
      <td>130</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
      <td>Latino</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>136</td>
      <td>107</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>White</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>74</td>
      <td>139</td>
      <td>117</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>White</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>63</td>
      <td>184</td>
      <td>145</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Indian</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>7</th>
      <td>67</td>
      <td>230</td>
      <td>99</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
      <td>White</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>8</th>
      <td>60</td>
      <td>198</td>
      <td>109</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Asian</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>9</th>
      <td>64</td>
      <td>169</td>
      <td>89</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>Latino</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The value of having done this is that boolean inputs can be represented using numerical values 0 and 1, just as boolean outputs can.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Black&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Black&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span> <span class="nb">int</span> <span class="p">)</span>
<span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Indian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Indian&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span> <span class="nb">int</span> <span class="p">)</span>
<span class="n">df_drug_response</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Height (in)</th>
      <th>Weight (lb)</th>
      <th>Systolic (mmHg)</th>
      <th>Response</th>
      <th>Prediction</th>
      <th>Correct</th>
      <th>Race</th>
      <th>Race=Black</th>
      <th>Race=Indian</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>72</td>
      <td>150</td>
      <td>90</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
      <td>Asian</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>191</td>
      <td>105</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Black</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>60</td>
      <td>112</td>
      <td>85</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
      <td>Black</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>69</td>
      <td>205</td>
      <td>130</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
      <td>Latino</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>136</td>
      <td>107</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>White</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>74</td>
      <td>139</td>
      <td>117</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>White</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>63</td>
      <td>184</td>
      <td>145</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Indian</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>67</td>
      <td>230</td>
      <td>99</td>
      <td>0</td>
      <td>0</td>
      <td>True</td>
      <td>White</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>60</td>
      <td>198</td>
      <td>109</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>Asian</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>64</td>
      <td>169</td>
      <td>89</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>Latino</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>These variables could then be added to our <code class="docutils literal notranslate"><span class="pre">predictors</span></code> DataFrame and used as numerical inputs to our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># handle warnings about slices</span>
<span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;Race=Black&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Black&#39;</span><span class="p">]</span>
<span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;Race=Indian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_drug_response</span><span class="p">[</span><span class="s1">&#39;Race=Indian&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>If no medical opinion had been present to suggest which races the model should focus on, we could create a boolean variable for each possible race.  There are some disadvantages to adding too many columns to your data, which we won’t cover here, but this is a common practice.  If all categories are converted into boolean variables, the result is called a <em>one-hot encoding,</em> because each row will have just one of the race columns equal to 1 and all others equal to 0.</p>
</div>
<div class="section" id="overfitting-and-underfitting-in-this-example">
<h2><span class="section-number">17.7. </span>Overfitting and underfitting in this example<a class="headerlink" href="#overfitting-and-underfitting-in-this-example" title="Permalink to this headline">¶</a></h2>
<p>Let’s return to the major theme introduced at the start of this chapter.  One way to overfit a regression or classification model is to throw in every variable you have access to as inputs to the model.  This is very similar to the example of polynomial regression used earlier, because polynomial regression essentially adds new columns <span class="math notranslate nohighlight">\(x^2,x^3,x^4,\ldots\)</span> as inputs.  A simple model will use just the most important variables, not necessarily every possible variable.</p>
<p>Statistics has many methods for evaluating which variables should be included or excluded from a model, and MA252 (Regression Analysis) covers such techniques.  But we have seen one way to discern which variables are the most impactful in logistic regression–examining the coefficients on those variables.  Variables whose coefficients are closer to zero are less likely to be indicative of signal and more likely to be indicative of noise.  Variables whose coefficients are larger (in absolute value, that is, farther from zero) are more likely to be indicative of the actual underlying structure of the problem.</p>
<p>Our in-class exercise on mortgage data will assess variable relevance using logistic regression coefficients.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chapter-16-matrices.html" title="previous page"><span class="section-number">16. </span>Relations as Matrices</a>
    <a class='right-next' id="next-link" href="course-schedule.html" title="next page"><span class="section-number">1. </span>Detailed Course Schedule</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Nathan Carter<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>